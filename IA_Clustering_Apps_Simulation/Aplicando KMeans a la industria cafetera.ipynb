{"cells":[{"cell_type":"markdown","source":["# Clustering  con K-means - Catado de cafe\n","Se tiene una base de datos con los resultados de diferentes catados de multiples muestras de cafe. \n","\n","Se desea realizar un agrupamiento de éstas muestras según sus métricas estadísticas. Entre ellas se encuentra la calificación promedio del catador certificado y niveles de sabor: Vainilla, floral, cereral, cocoa, alcohol, fermentado, tostado, oscuro, amargo, entre otros.\n","\n","En este caso se hace uso del algorítmo KMeans, que se explica más adelante."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Imports\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","import pandas as pd\n","\n","%matplotlib inline"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["## Importando Dataset y visualizando sus Características"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["cafes = pd.read_csv('../datasets/catacafe.csv',engine='python')\n","cafes.info()"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["## Mostrar las primeras filas para una previsualización del orden de los datos"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["cafes.head()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Se puede ver que la columna \"Cafe\" es el índice numérico de la muestra, pero que ya se ha enumerado con el método de lectura, por ello, se procede a eliminarla."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["cafes = cafes.drop(['Cafe'],axis=1)\n","cafes.head()\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Se obtienen las variables estadísticas de los datos por columna."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["cafes.describe()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Se normalizan los datos en un rango adecuado y se vuelven a obtener sus métricas"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["cafes_normalizado = (cafes - cafes.min())/(cafes.max()-cafes.min())\n","cafes_normalizado.describe()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Se puede observar que ahora los datos tienen valores entre cero y uno, max y min.\n","\n","## Ahora con este preprocesamiento se tienen datos ordenados, numéricos y normalizados, listos para un agrupamiento óptimo.\n","El método de KMeans presenta gran efectividad y velocidad para datos no tan amplios, sin embargo, su principal debilidad es la selección de parámetros de entrada, entiéndase número de clusters a realizar. Como este valor no se conoce, se debe usar algún método para óptimizar su implementación, en este caso se utilizará el método del codo de Jambú para encontrar un número de clusters óptimo:"],"metadata":{}},{"cell_type":"markdown","source":["## Obtencion del gráfico del Codo de Jambú"],"metadata":{}},{"cell_type":"markdown","source":["Se desean que los clusteres sean lo más separados entre sí y que sus elementos sean lo más cercanos entre sí. para ello se utiliza la medida WCSS: suma de los cuadrados de las distancias de cada punto de datos, en todos los grupos a sus respectivos centroides, es decir, es una medida de similitud.\n","La idea es minimizar esta suma. Para ello se obtiene la inercia de cada clustering realizado con KMeans para un cierto número de grupos, desde 1 hasta uno deseado, estos valores obtenidos en cada iteración se almacena en WCSS, donde luego se imprimen en una gráfica para su análisis."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["num_clusters = 10\n","wcss = []\n","for i in range(1,num_clusters+1):\n","    kmeans_model = KMeans(n_clusters=i,max_iter=300)\n","    kmeans_model.fit(cafes_normalizado)\n","    wcss.append(kmeans_model.inertia_)\n","\n","## Ahora se grafican los resultados:\n","\n","plt.plot(range(1,num_clusters+1),wcss)\n","plt.title(\"Codo de Jambú\")\n","plt.xlabel(\"Número de Clusters\")\n","plt.ylabel(\"WCSS\")\n","plt.show()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Se observa que le número de clusteres optimo es 3, para este metodo y este dataset. Ahora se procede a utilizar el metodo Kmeans con este parametro. Igual que anteriormente, se crea el modelo de clustering y luego se aplica con .fit"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["agrupamiento =  KMeans(n_clusters=3, max_iter=300) \n","agrupamiento.fit(cafes_normalizado)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Este metodo crea un atributo label_ dentro del modelo clustering generado. Se agrega esta calificacion al archivo original del Dataset:"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["cafes['KMeans_clusters'] = agrupamiento.labels_\n","cafes.head()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Visualización de los clusters Generados\n","Los datos tienen múltiples variables que los caracterizan, en este caso se desea visualizar un gráfico lo mayor resumido posible, y en la naturaleza humana se alcanzan a visualizar hasta tres dimensiones.\n","\n","Para efectos didácticos, se mostraran en dos dimensiones ¿Cuales? se seleccionan las variables que mejor caractericen a todos los datos, para ello se hace uso del Análisis de Componentes Principales (PCA) para reducir el número de variables a analizar, en este caso a visualizar.\n","Se hace uso del paquete descomposition de sklearn y se crea un dataframe a partir de estos componentes para graficarlo."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from sklearn.decomposition import PCA\n","\n","pca = PCA(n_components=2)                         # Dos componentes principales\n","pca_cafes = pca.fit_transform(cafes_normalizado)\n","pca_cafes_df = pd.DataFrame(data= pca_cafes, columns=['Componente_1', 'Componente_2'])\n","pca_names_cafes = pd.concat([pca_cafes_df, cafes[['KMeans_clusters']]], axis=1)\n","\n","# veamos el resultado de los datos procesados:\n","pca_names_cafes  "],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Graficar el dataframe procesado\n","Ahora se configura la figura plot a mostrar con estos datos obtenidos"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Configurando la figura plot\n","fig = plt.figure(figsize= (7,7))                                                    # área del gráfico\n","grafico = fig.add_subplot(1,1,1)                                                    # Se delimita el área subplot a una sola figura\n","grafico.set_xlabel('Componente 1',fontsize = 12 )                                   # Etiqueta de eje X y tamaño de letra\n","grafico.set_ylabel('Componente 2',fontsize = 12 )                                   # Etiqueta de eje Y y tamaño de letra\n","grafico.set_title('Componentes Principales - Clustering Kmeans',fontsize = 20 )     # Setear el título de la figura\n","Colores = np.array([\"blue\", \"orange\", \"green\"])                                     # Vector de nombres de colores a llamar. Deben haber tantos colores como clusters(etiquetas) generados \n","grafico.scatter(x=pca_names_cafes.Componente_1, y=pca_names_cafes.Componente_2, c=Colores[pca_names_cafes.KMeans_clusters], s=40)   #llamado al método de figura de puntos de dispersión.\n","plt.show()                                                                          # Graficar"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Guardar los datos generados\n","Se procede a guardar el dataframe en formato csv:"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Se crea un archivo csv en la carpeta Results\n","cafes.to_csv('../Results/cafe-kmeans.csv')"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# Ejercicios/ Experimentos propuestos\n","\n","## 1. Elija un valor aleatorio para el número de clusters a implementar, suponiendo que no conoce el resultado del método Codo de Jambú. ¿Cómo cambia el resultado? ¿Qu+e se nota?\n","## 2. ¿Qué sucede al aumentar o disminuir el número de clusters a implementar en la llamada a KMeans? ¿Por qué?\n","## 3. ¿Qué sucede con los clusters al aumentar o disminuir significativamente el número de iteraciones máximo (seteado en 300) al usar el metodo del Codo de Jambú y en la llamada a KMeans? ¿Por qué?\n","## 4. Explique las ventajas y desventajas que tiene el algoritmo KMeans. Puede investigar diferentes fuentes.\n","## 5. Aumente el número de PCA a 3 componentes y grafíquelo en 3 Dimensiones. ¿Qué es lo que cambió y qué se está añadiendo?"],"metadata":{}},{"cell_type":"markdown","source":["## Experimentos a realizar\n","Aumentar las variables PCA a 3, configurando el grafico para mostrarlo."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["pca = PCA(n_components=3)\n","pca_cafes = pca.fit_transform(cafes_normalizado)\n","pca_cafes_df = pd.DataFrame(data= pca_cafes, columns=['Componente_1', 'Componente_2','Componente_3'])\n","pca_names_cafes = pd.concat([pca_cafes_df, cafes[['KMeans_clusters']]], axis=1)\n","\n","pca_names_cafes   # veamos el resultado de los datos procesados:"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Graficamos este nuevo dataframe en 3D\n","#from mpl_toolkits.mplot3d import Axes3D  #otra forma de plotearlo, permite interactividad\n","#grafico = Axes3D(fig)\n","\n","fig = plt.figure(figsize= (12,12))\n","grafico = fig.add_subplot(111, projection='3d')\n","\n","x = pca_names_cafes.Componente_1\n","y = pca_names_cafes.Componente_2\n","z = pca_names_cafes.Componente_3\n","\n","grafico.set_xlabel('Componente 1',fontsize = 12 )\n","grafico.set_ylabel('Componente 2',fontsize = 12 )\n","grafico.set_zlabel('Componente 3',fontsize = 12 )\n","grafico.set_title('3 Componentes principales - Clustering Kmeans',fontsize = 20 )\n","Colores = np.array([\"blue\", \"orange\", \"green\"])\n","\n","# Agregamos los puntos en el plano 3D\n","grafico.scatter(x, y, z, c=Colores[pca_names_cafes.KMeans_clusters], marker='o')\n","plt.show()\n","\n","# Como se puede observar, se está agregando la tercer componente más representativa del conjunto de datos, obtenida por medio de PCA, alcanzando la maxima visualizacion posible.\n","# Es posible mover el gráfico 3D en algunos visualizadores y observar mejor la relacion entre los diferentes clusters."],"outputs":[],"metadata":{}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}